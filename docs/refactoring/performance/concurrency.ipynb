{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to concurrency\n",
    "\n",
    "When developing code, there can often be trade-offs between different implementations. However, at the beginning of the development of an algorithm, it is usually counterproductive to worry about the efficiency of the code.\n",
    "\n",
    "> *«We should forget about small efficiencies, say about 97% of the time:\n",
    "> premature optimization is the root of all evil. Yet we should not pass up\n",
    "> our opportunities in that critical 3%.»*\n",
    "\n",
    "– Donald Knuth, founder of [Literate Programming](http://www.literateprogramming.com/), in Computer Programming as an Art (1974)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Martelli’s model of scalability\n",
    "\n",
    "| Number of cores  | Description                            |\n",
    "| ---------------- | -------------------------------------- |\n",
    "| 1                | Single thread and single process       |\n",
    "| 2–8              | Multiple threads and multiple processes|\n",
    "| >8               | Distributed processing                 |\n",
    "\n",
    "Martelli’s observation: In the course of time, the second category becomes more and more insignificant: individual cores are becoming more and more powerful and large data sets are getting bigger and bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Interpreter Lock (GIL)\n",
    "\n",
    "CPython has a lock on its internally shared global state. As a result, no more than one thread can run at the same time.\n",
    "\n",
    "The GIL is not a big problem for I/O-heavy applications; however, using threading will slow down CPU-heavy applications. Accordingly, multi-processing is exciting for us to get more CPU cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Literate programming* and *Martelli's model of scalability* determined the design decisions on Python’s performance for a long time. Little has changed in this assessment to this day: Contrary to intuitive expectations, more CPUs and threads in Python initially lead to less efficient applications. However, the [Gilectomy](https://pythoncapi.readthedocs.io/gilectomy.html) project, which was supposed to replace the GIL, also encountered another problem: the Python C API exposes too many implementation details. With this, however, performance improvements would quickly lead to incompatible changes, which then seem unacceptable, especially in a language as popular as Python. Nevertheless, there are already some solutions:\n",
    "\n",
    "* [Numba](http://numba.pydata.org/) is a JIT compiler that translates mainly scientific Python and NumPy code into fast machine code.\n",
    "* [PyPy](https://www.pypy.org/) with a more universal JIT compiler, but which has to emulate existing C extension like NumPy, which is really inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading, multiprocessing and asynchronous communication\n",
    "\n",
    "### Multithreading\n",
    "\n",
    "#### Pros\n",
    "\n",
    "* Threads have the advantage of sharing a common status. However, this can also lead to race conditions, ie the results of an operation can depend on the timing of certain individual operations.\n",
    "\n",
    "* Threads change preemptively, see [Preemptive multitasking](https://en.wikipedia.org/wiki/Computer_multitasking#Preemptive_multitasking). This is useful because you don’t have to add any explicit code to cause the task to switch.\n",
    "\n",
    "* Threading usually works with existing code and tools as long as locks are added to critical sections.\n",
    "\n",
    "* Threads require very little tooling: [Lock](https://docs.python.org/3/library/threading.html#threading.Lock) and [Queues](https://docs.python.org/3/library/queue.html).\n",
    "\n",
    "#### Cons\n",
    "\n",
    "* The cost of this convenience is that you have to assume that such a change is possible at any time. Accordingly, critical areas must be protected with locks.\n",
    "\n",
    "* The performance limit for threads is one CPU minus the costs for task switches and synchronization efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "\n",
    "#### Pros\n",
    "\n",
    "* The strength of processes is to be independent of one another.\n",
    "\n",
    "#### Cons\n",
    "\n",
    "* However, they do not communicate with each other either. Therefore, [Interprocess Communication (IPC)](https://docs.python.org/3/library/ipc.html), [object pickling](https://docs.python.org/3/library/pickle.html) and other overheads are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous communication\n",
    "\n",
    "#### Pros\n",
    "\n",
    "* Async switches cooperatively, so you have to explicitly add [yield](https://docs.python.org/3/reference/simple_stmts.html#yield) or [await](https://docs.python.org/3/reference/expressions.html#await) for a task switch. This allows you to control when these tasks switches and, if necessary, locks and synchronisations should take place. You can therefore keep the effort for task switches very low. In addition, calling a pure Python function has more overhead than requesting a generator or awaitable again – that is, async is very cheap.\n",
    "* Async can improve CPU usage because it can reduce the usual overhead.\n",
    "* With complex systems, async is much easier than threads with locks.\n",
    "\n",
    "#### Cons\n",
    "\n",
    "* Async requires a large number of tools: [futures](https://docs.python.org/3/library/asyncio-task.html#future), [Event Loops](https://docs.python.org/3/library/asyncio-eventloops.html), and non-blocking versions of almost everything."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4",
   "language": "python",
   "name": "python-374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
